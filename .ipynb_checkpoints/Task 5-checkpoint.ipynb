{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the ensamble model VotingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from casestudy_tools import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the preprocessed data set for Organics.\n",
    "df = preprocess()\n",
    "\n",
    "# Import necssary packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Sets target column to ORGYN\n",
    "target_dataset = df['ORGYN']\n",
    "# Removes ORGYN from the dataset in order to avoid false predictor.\n",
    "dataset = df.drop(['ORGYN'], axis=1)\n",
    "\n",
    "# Sets random state to 10. This will be kept consistently throughout the case study.\n",
    "random_state = 10\n",
    "# Sets the test size to be 30% of the total data set.\n",
    "test_size = 0.3\n",
    "\n",
    "# Transform the dataset into a matrix.\n",
    "dataset_matrix = dataset.as_matrix()\n",
    "\n",
    "# Splits the data into train and test sets.\n",
    "dataset_train, dataset_test, target_dataset_train, target_dataset_test = train_test_split(dataset_matrix, target_dataset, test_size=test_size, stratify=target_dataset, random_state=random_state)\n",
    "\n",
    "# Updates the global variables with the test and train data\n",
    "dt_x_train = dataset_train\n",
    "dt_x_test = dataset_test\n",
    "dt_y_train = target_dataset_train\n",
    "dt_y_test = target_dataset_test\n",
    "\n",
    "\n",
    "# GridSearchCV parameters\n",
    "params = {'criterion': ['gini', 'entropy'],\n",
    "          'max_depth': range(2, 5),\n",
    "          'min_samples_leaf': range(1, 2)}\n",
    "\n",
    "cross_validation_optimal_model = GridSearchCV(param_grid=params,\n",
    "                                      estimator=DecisionTreeClassifier(random_state=random_state),\n",
    "                                      cv=10)\n",
    "cross_validation_optimal_model.fit(dataset_train, target_dataset_train)\n",
    "\n",
    "train_accuracy_optimal_cv = cross_validation_optimal_model.score(dataset_train, target_dataset_train)\n",
    "test_accuracy_optimal_cv = cross_validation_optimal_model.score(dataset_test, target_dataset_test)\n",
    "\n",
    "# test the best model\n",
    "target_prediction = cross_validation_optimal_model.predict(dataset_test)\n",
    "\n",
    "    # Prints train and test accuracy.\n",
    "print(\"CV Tuned Decision Tree Statistics:\")\n",
    "print(\"Train Accuracy:\", cross_validation_optimal_model.score(dataset_train, target_dataset_train))\n",
    "print(\"Test Accuracy:\", cross_validation_optimal_model.score(dataset_test, target_dataset_test))\n",
    "\n",
    "# Printing a classification report of the model.\n",
    "print(\"\")\n",
    "print(\"Classification Report:\")\n",
    "target_predict = cross_validation_optimal_model.predict(dataset_test)\n",
    "print(classification_report(target_dataset_test, target_predict))\n",
    "print(\"Number of nodes in the decision tree:\", cross_validation_optimal_model.best_estimator_.tree_.node_count)\n",
    "\n",
    "dt_model = cross_validation_optimal_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# preprocessing step\n",
    "df = preprocess()\n",
    "\n",
    "# random state\n",
    "rs = 10\n",
    "\n",
    "# train test split\n",
    "y = df['ORGYN']\n",
    "X = df.drop(['ORGYN'], axis=1)\n",
    "X_mat = X.as_matrix()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_mat, y, test_size=0.3, stratify=y, random_state=rs)\n",
    "\n",
    "\n",
    "# initialise a standard scaler object\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train, y_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "df_log = df.copy()\n",
    "\n",
    "#Create X, y and train test data partitions\n",
    "# create X, y and train test data partitions\n",
    "y_log = df_log['ORGYN']\n",
    "X_log = df_log.drop(['ORGYN'], axis=1)\n",
    "X_mat_log = X_log.as_matrix()\n",
    "X_train_log, X_test_log, y_train_log, y_test_log = train_test_split(X_mat_log, y_log, test_size=0.3, stratify=y_log, \n",
    "                                                                    random_state=rs)\n",
    "\n",
    "# standardise them again\n",
    "scaler_log = StandardScaler()\n",
    "X_train_log = scaler_log.fit_transform(X_train_log, y_train_log)\n",
    "X_test_log = scaler_log.transform(X_test_log)\n",
    "\n",
    "print(\"Using RFECV\")\n",
    "#Q3 Feature Transformation\n",
    "from sklearn.feature_selection import RFECV\n",
    "rfe = RFECV(estimator = LogisticRegression(random_state=rs), cv=10)\n",
    "rfe.fit(X_train, y_train) # run the RFECV\n",
    "\n",
    "print(\"RFECV\")\n",
    "\n",
    "#test the performance\n",
    "X_train_sel = rfe.transform(X_train)\n",
    "X_test_sel = rfe.transform(X_test)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from casestudy_tools import get_decision_tree\n",
    "#from casestudy_tools import analyse_feature_importance\n",
    "\n",
    "params = {'criterion': ['gini', 'entropy'],\n",
    "          'max_depth': range(2, 5),\n",
    "          'min_samples_leaf': range(1,2)}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params, estimator=DecisionTreeClassifier(random_state=rs), cv=10)\n",
    "cv.fit(X_train_log, y_train_log)\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# use the trained best decision tree from GridSearchCV to select features\n",
    "# supply the prefit=True parameter to stop SelectFromModel to re-train the model\n",
    "selectmodel = SelectFromModel(cv.best_estimator_, prefit=True)\n",
    "X_train_sel_model = selectmodel.transform(X_train_log)\n",
    "X_test_sel_model = selectmodel.transform(X_test_log)\n",
    "\n",
    "# Grid search cv for RFE SELECTION MODEL (BEST MODEL)\n",
    "params = {'C': [pow(10, x) for x in range(-6, 4)]}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params, estimator=LogisticRegression(random_state=rs), cv=10, n_jobs=-1)\n",
    "cv.fit(X_train_sel_model, y_train_log)\n",
    "\n",
    "print(\"Logistic Regression Model Statistics:\")\n",
    "print(\"Train accuracy:\", cv.score(X_train_sel_model, y_train_log))\n",
    "print(\"Test accuracy:\", cv.score(X_test_sel_model, y_test_log))\n",
    "\n",
    "log_reg_x_train = X_train_sel_model\n",
    "log_reg_x_test  = X_test_sel_model\n",
    "log_reg_y_train = y_train_log\n",
    "log_reg_y_test  = y_test_log\n",
    "\n",
    "# test the best model\n",
    "y_pred = cv.predict(X_test_sel_model)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_log, y_pred))\n",
    "\n",
    "# print parameters of the best model\n",
    "print(cv.best_params_)\n",
    "\n",
    "\n",
    "log_reg_model = cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "rs = 10\n",
    "\n",
    " # Gets the preprocessed data set for Organics.\n",
    "df = preprocess()\n",
    "\n",
    "y = df['ORGYN']\n",
    "X = df.drop(['ORGYN'], axis=1)\n",
    "X_mat = X.as_matrix()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_mat, y, test_size=0.3, stratify=y, random_state=rs)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train, y_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Updates the global variables with the test and train data\n",
    "nn_x_train = X_train\n",
    "nn_x_test = X_test\n",
    "nn_y_train = y_train\n",
    "nn_y_test = y_test\n",
    "\n",
    "\n",
    "\n",
    "params = {'hidden_layer_sizes': [(3)], 'alpha': [0.0001]}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params, estimator=MLPClassifier(random_state=rs), cv=10, n_jobs=-1)\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "y_pred = cv.predict(X_test)\n",
    "print(\"Neural Network Model Statistics:\")\n",
    "print(\"Train accuracy:\", cv.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", cv.score(X_test, y_test))\n",
    "\n",
    "nn_x_train = X_train\n",
    "nn_x_test  = X_test\n",
    "nn_y_train = y_train\n",
    "nn_y_test  = y_test\n",
    "\n",
    "y_pred = cv.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "nn_model = cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialise the classifier with 3 different estimators\n",
    "ensemble_voting_model = VotingClassifier(estimators=[('dt', dt_model), ('lr', log_reg_model), ('nn', nn_model)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Divides a new set of training and testdata from the given dataset.\n",
    "df = tools.preprocess()\n",
    "\n",
    "# Building a decision tree using the default settings.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Sets target column to ORGYN\n",
    "target_dataset = df['ORGYN']\n",
    "# Removes ORGYN from the dataset in order to avoid false predictor.\n",
    "dataset = df.drop(['ORGYN'], axis=1)\n",
    "\n",
    "# Sets random state to 10. This will be kept consistently throughout the case study.\n",
    "random_state = 10\n",
    "# Sets the test size to be 30% of the total data set.\n",
    "test_size = 0.3\n",
    "\n",
    "# Transform the dataset into a matrix.\n",
    "dataset_matrix = dataset.as_matrix()\n",
    "\n",
    "# Splits the data into train and test sets.\n",
    "dataset_train, dataset_test, target_dataset_train, target_dataset_test = train_test_split(dataset_matrix,\n",
    "                                                                                          target_dataset,\n",
    "                                                                                          test_size=test_size,\n",
    "                                                                                          stratify=target_dataset,\n",
    "                                                                                          random_state=random_state\n",
    "                                                                                         )\n",
    "\n",
    "scaler = StandardScaler()\n",
    "dataset_train_scaled = scaler.fit_transform(dataset_train, target_dataset_train)\n",
    "dataset_test_scaled = scaler.transform(dataset_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed for accuracy score\n",
    "from sklearn.metrics import roc_auc_score, classification_report, accuracy_score\n",
    "\n",
    "# fit the voting classifier to training data\n",
    "ensemble_voting_model.fit(dataset_train_scaled, target_dataset_train)\n",
    "\n",
    "# evaluate train and test accuracy\n",
    "print(\"Ensemble soft train accuracy:\", ensemble_voting_model.score(dataset_train_scaled, target_dataset_train))\n",
    "print(\"Ensemble soft test accuracy:\", ensemble_voting_model.score(dataset_test_scaled, target_dataset_test))\n",
    "\n",
    "# evaluate ROC auc score\n",
    "y_pred_proba_ensemble = ensemble_voting_model.predict_proba(dataset_test_scaled)\n",
    "roc_index_ensemble = roc_auc_score(target_dataset_test, y_pred_proba_ensemble[:, 1])\n",
    "print(\"ROC score of soft voting classifier:\", roc_index_ensemble)\n",
    "\n",
    "y_pred_ensemble = ensemble_voting_model.predict(dataset_test_scaled)\n",
    "print(\"Classification Report for Ensemble:\")\n",
    "print(classification_report(target_dataset_test, y_pred_ensemble))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Task 5.2</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred_dt = dt_model.predict(dt_x_test)\n",
    "y_pred_log_reg = log_reg_model.predict(log_reg_x_test)\n",
    "y_pred_nn = nn_model.predict(nn_x_test)\n",
    "\n",
    "print(\"Accuracy score on test for Decision Tree:\", accuracy_score(dt_y_test, y_pred_dt))\n",
    "print(\"Accuracy score on test for logistic regression:\", accuracy_score(log_reg_y_test, y_pred_log_reg))\n",
    "print(\"Accuracy score on test for Neural Networks:\", accuracy_score(nn_y_test, y_pred_nn))\n",
    "print(\"Accuracy score on test for Ensemble:\", accuracy_score(target_dataset_test, y_pred_ensemble))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report for Decision Tree:\")\n",
    "print(classification_report(dt_y_test, y_pred_dt))\n",
    "print(\"Classification Report for logistic regression:\")\n",
    "print(classification_report(log_reg_y_test, y_pred_log_reg))\n",
    "print(\"Classification Report for Neural Networks:\")\n",
    "print(classification_report(nn_y_test, y_pred_nn))\n",
    "print(\"Classification Report for Ensemble:\")\n",
    "print(classification_report(target_dataset_test, y_pred_ensemble))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred_proba_dt = dt_model.predict_proba(dt_x_test)\n",
    "y_pred_proba_log_reg = log_reg_model.predict_proba(log_reg_x_test)\n",
    "y_pred_proba_nn = nn_model.predict_proba(nn_x_test)\n",
    "y_pred_proba_ensemble = ensemble_voting_model.predict_proba(dataset_test_scaled)\n",
    "\n",
    "roc_index_dt = roc_auc_score(dt_y_test, y_pred_proba_dt[:, 1])\n",
    "roc_index_log_reg = roc_auc_score(log_reg_y_test, y_pred_proba_log_reg[:, 1])\n",
    "roc_index_nn = roc_auc_score(nn_y_test, y_pred_proba_nn[:, 1])\n",
    "roc_index_ensemble = roc_auc_score(target_dataset_test, y_pred_proba_ensemble[:, 1])\n",
    "\n",
    "print(\"ROC index on test for DT:\", roc_index_dt)\n",
    "print(\"ROC index on test for logistic regression:\", roc_index_log_reg)\n",
    "print(\"ROC index on test for NN:\", roc_index_nn)\n",
    "print(\"ROC index on test for Ensemble:\", roc_index_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Gets the false positive rate, true positive rate and thresholds used for each model\n",
    "fpr_dt, tpr_dt, thresholds_dt = roc_curve(dt_y_test, y_pred_proba_dt[:,1])\n",
    "fpr_log_reg, tpr_log_reg, thresholds_log_reg = roc_curve(log_reg_y_test, y_pred_proba_log_reg[:,1])\n",
    "fpr_nn, tpr_nn, thresholds_nn = roc_curve(nn_y_test, y_pred_proba_nn[:,1])\n",
    "fpr_ensemble, tpr_ensemble, thresholds_ensemble = roc_curve(target_dataset_test, y_pred_proba_ensemble[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Sets the color to white.\n",
    "params = {\"ytick.color\" : \"w\",\n",
    "          \"xtick.color\" : \"w\",\n",
    "          \"axes.labelcolor\" : \"w\",\n",
    "          \"axes.edgecolor\" : \"w\"}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "plt.plot(fpr_dt, tpr_dt, label='ROC Curve for DT {:.3f}'.format(roc_index_dt), color='red', lw=0.5)\n",
    "plt.plot(fpr_log_reg, tpr_log_reg, label='ROC Curve for Log reg {:.3f}'.format(roc_index_log_reg), color='green', lw=0.5)\n",
    "plt.plot(fpr_nn, tpr_nn, label='ROC Curve for NN {:.3f}'.format(roc_index_nn), color='darkorange', lw=0.5)\n",
    "plt.plot(fpr_ensemble, tpr_ensemble, label='ROC Curve for Ensemble {:.3f}'.format(roc_index_ensemble), color='yellow', lw=0.5)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=0.5, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC chart for predicting organic purchase', color=\"w\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
