{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22223 entries, 0 to 22222\n",
      "Data columns (total 37 columns):\n",
      "AGE                    22223 non-null float64\n",
      "BILL                   22223 non-null float64\n",
      "ORGYN                  22223 non-null int64\n",
      "AFFL                   22223 non-null int64\n",
      "LTIME                  22223 non-null float64\n",
      "GENDER_F               22223 non-null uint8\n",
      "GENDER_M               22223 non-null uint8\n",
      "GENDER_U               22223 non-null uint8\n",
      "TV_REG_Border          22223 non-null uint8\n",
      "TV_REG_C Scotland      22223 non-null uint8\n",
      "TV_REG_East            22223 non-null uint8\n",
      "TV_REG_London          22223 non-null uint8\n",
      "TV_REG_Midlands        22223 non-null uint8\n",
      "TV_REG_N East          22223 non-null uint8\n",
      "TV_REG_N Scot          22223 non-null uint8\n",
      "TV_REG_N West          22223 non-null uint8\n",
      "TV_REG_S & S East      22223 non-null uint8\n",
      "TV_REG_S West          22223 non-null uint8\n",
      "TV_REG_Ulster          22223 non-null uint8\n",
      "TV_REG_Wales & West    22223 non-null uint8\n",
      "TV_REG_Yorkshire       22223 non-null uint8\n",
      "NGROUP_A               22223 non-null uint8\n",
      "NGROUP_B               22223 non-null uint8\n",
      "NGROUP_C               22223 non-null uint8\n",
      "NGROUP_D               22223 non-null uint8\n",
      "NGROUP_E               22223 non-null uint8\n",
      "NGROUP_F               22223 non-null uint8\n",
      "NGROUP_U               22223 non-null uint8\n",
      "REGION_Midlands        22223 non-null uint8\n",
      "REGION_North           22223 non-null uint8\n",
      "REGION_Scottish        22223 non-null uint8\n",
      "REGION_South East      22223 non-null uint8\n",
      "REGION_South West      22223 non-null uint8\n",
      "CLASS_Gold             22223 non-null uint8\n",
      "CLASS_Platinum         22223 non-null uint8\n",
      "CLASS_Silver           22223 non-null uint8\n",
      "CLASS_Tin              22223 non-null uint8\n",
      "dtypes: float64(3), int64(2), uint8(32)\n",
      "memory usage: 1.5 MB\n"
     ]
    }
   ],
   "source": [
    "import casestudy_tools as tools\n",
    "df = tools.preprocess()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data PreProcessing</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"datasets/organics.csv\")\n",
    "#df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22223 entries, 0 to 22222\n",
      "Data columns (total 12 columns):\n",
      "GENDER    19711 non-null object\n",
      "DOB       22223 non-null object\n",
      "EDATE     22223 non-null object\n",
      "AGE       20715 non-null float64\n",
      "TV_REG    21758 non-null object\n",
      "NGROUP    21549 non-null object\n",
      "BILL      22223 non-null float64\n",
      "REGION    21758 non-null object\n",
      "CLASS     22223 non-null object\n",
      "ORGYN     22223 non-null int64\n",
      "AFFL      21138 non-null float64\n",
      "LTIME     21942 non-null float64\n",
      "dtypes: float64(4), int64(1), object(7)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['CUSTID', 'LCDATE', 'ORGANICS', 'AGEGRP1', 'AGEGRP2'], axis = 1)\n",
    "df = df.drop(['NEIGHBORHOOD'], axis = 1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculates the years between DOB and EDATE and adds that value to age for missing values.\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "dateformat = '%Y-%m-%d'\n",
    "edate = pd.Timestamp(df['EDATE'][0])\n",
    "df['DOB'] = pd.to_datetime(df['DOB'], format=dateformat)    # 1\n",
    "df['DOB'] = df['DOB'].where(df['DOB'] < edate, df['DOB'] -  np.timedelta64(100, 'Y'))   # 2\n",
    "df['AGE'] = (edate - df['DOB']).astype('<m8[Y]')    # 3\n",
    "\n",
    "df['AGE']\n",
    "df = df.drop(['EDATE', 'DOB'], axis = 1)\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# denote errorneous values in AFFL column. Should be on scale 1-30.\n",
    "mask = df['AFFL'] < 1\n",
    "df.loc[mask, 'AFFL'] = 1\n",
    "mask = df['AFFL'] > 30\n",
    "df.loc[mask, 'AFFL'] = 30\n",
    "\n",
    "# Fill mean values for AFFL column.\n",
    "df['AFFL'].fillna(df['AFFL'].mean(), inplace=True)\n",
    "# Convert the scale to integer. Not sure if this is necessary.\n",
    "df['AFFL'] = df['AFFL'].astype(int)\n",
    "#df.info()\n",
    "#df['AFFL'].value_counts(bins=8)\n",
    "#sorted(df['AFFL'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fills mean values based on age for loyalty time. \n",
    "means = df.groupby(['AGE'])['LTIME'].mean()\n",
    "df = df.set_index(['AGE'])\n",
    "df['LTIME'] = df['LTIME'].fillna(means)\n",
    "df = df.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['GENDER'].fillna('U', inplace=True)\n",
    "#df['GENDER'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22223 entries, 0 to 22222\n",
      "Data columns (total 37 columns):\n",
      "AGE                    22223 non-null float64\n",
      "BILL                   22223 non-null float64\n",
      "ORGYN                  22223 non-null int64\n",
      "AFFL                   22223 non-null int32\n",
      "LTIME                  22223 non-null float64\n",
      "GENDER_F               22223 non-null uint8\n",
      "GENDER_M               22223 non-null uint8\n",
      "GENDER_U               22223 non-null uint8\n",
      "TV_REG_Border          22223 non-null uint8\n",
      "TV_REG_C Scotland      22223 non-null uint8\n",
      "TV_REG_East            22223 non-null uint8\n",
      "TV_REG_London          22223 non-null uint8\n",
      "TV_REG_Midlands        22223 non-null uint8\n",
      "TV_REG_N East          22223 non-null uint8\n",
      "TV_REG_N Scot          22223 non-null uint8\n",
      "TV_REG_N West          22223 non-null uint8\n",
      "TV_REG_S & S East      22223 non-null uint8\n",
      "TV_REG_S West          22223 non-null uint8\n",
      "TV_REG_Ulster          22223 non-null uint8\n",
      "TV_REG_Wales & West    22223 non-null uint8\n",
      "TV_REG_Yorkshire       22223 non-null uint8\n",
      "NGROUP_A               22223 non-null uint8\n",
      "NGROUP_B               22223 non-null uint8\n",
      "NGROUP_C               22223 non-null uint8\n",
      "NGROUP_D               22223 non-null uint8\n",
      "NGROUP_E               22223 non-null uint8\n",
      "NGROUP_F               22223 non-null uint8\n",
      "NGROUP_U               22223 non-null uint8\n",
      "REGION_Midlands        22223 non-null uint8\n",
      "REGION_North           22223 non-null uint8\n",
      "REGION_Scottish        22223 non-null uint8\n",
      "REGION_South East      22223 non-null uint8\n",
      "REGION_South West      22223 non-null uint8\n",
      "CLASS_Gold             22223 non-null uint8\n",
      "CLASS_Platinum         22223 non-null uint8\n",
      "CLASS_Silver           22223 non-null uint8\n",
      "CLASS_Tin              22223 non-null uint8\n",
      "dtypes: float64(3), int32(1), int64(1), uint8(32)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "rs = 10\n",
    "\n",
    "y = df['ORGYN']\n",
    "X = df.drop(['ORGYN'], axis=1)\n",
    "X_mat = X.as_matrix()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_mat, y, test_size=0.3, stratify=y, random_state=rs)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train, y_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8254049884289021\n",
      "Test accuracy: 0.8128093595320234\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.93      0.88      5015\n",
      "          1       0.69      0.45      0.54      1652\n",
      "\n",
      "avg / total       0.80      0.81      0.80      6667\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=10, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(random_state=rs)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", model.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", model.score(X_test, y_test))\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.825404988429\n",
      "Test accuracy: 0.812809359532\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.93      0.88      5015\n",
      "          1       0.69      0.45      0.54      1652\n",
      "\n",
      "avg / total       0.80      0.81      0.80      6667\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=10, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(max_iter=100, random_state=rs)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", model.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", model.score(X_test, y_test))\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.825404988429\n",
      "Test accuracy: 0.812809359532\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.93      0.88      5015\n",
      "          1       0.69      0.45      0.54      1652\n",
      "\n",
      "avg / total       0.80      0.81      0.80      6667\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=80, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=10, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(max_iter=80, random_state=rs)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", model.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", model.score(X_test, y_test))\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15556, 36)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.813962458215\n",
      "Test accuracy: 0.817159142043\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.95      0.89      5015\n",
      "          1       0.72      0.42      0.53      1652\n",
      "\n",
      "avg / total       0.81      0.82      0.80      6667\n",
      "\n",
      "{'hidden_layer_sizes': (5,)}\n"
     ]
    }
   ],
   "source": [
    "params = {'hidden_layer_sizes': [(x,) for x in range(5, 36, 15)]}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params, estimator=MLPClassifier(random_state=rs), cv=3, n_jobs=-1)\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", cv.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", cv.score(X_test, y_test))\n",
    "\n",
    "y_pred = cv.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.814412445359\n",
      "Test accuracy: 0.818959052047\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.94      0.89      5015\n",
      "          1       0.72      0.44      0.55      1652\n",
      "\n",
      "avg / total       0.81      0.82      0.80      6667\n",
      "\n",
      "{'hidden_layer_sizes': (3,)}\n"
     ]
    }
   ],
   "source": [
    "# new parameters\n",
    "params = {'hidden_layer_sizes': [(3,), (5,), (7,), (9,)]}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params, estimator=MLPClassifier(random_state=rs), cv=10, n_jobs=-1)\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", cv.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", cv.score(X_test, y_test))\n",
    "\n",
    "y_pred = cv.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'hidden_layer_sizes': [(3,)], 'alpha': [0.0001]}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params, estimator=MLPClassifier(random_state=rs), cv=10, n_jobs=-1)\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", cv.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", cv.score(X_test, y_test))\n",
    "\n",
    "y_pred = cv.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns_to_transform = ['AGE', 'AFFL', 'GENDER_F', 'GENDER_M',\n",
    "                        'GENDER_U', 'REGION_North']\n",
    "\n",
    "# copy the dataframe\n",
    "df_log = df.copy()\n",
    "\n",
    "# transform the columns with np.log\n",
    "for col in columns_to_transform:\n",
    "    df_log[col] = df_log[col].apply(lambda x: x+1)\n",
    "    df_log[col] = df_log[col].apply(np.log)\n",
    "    \n",
    "# create X, y and train test data partitions\n",
    "y_log = df_log['ORGYN']\n",
    "X_log = df_log.drop(['ORGYN'], axis=1)\n",
    "X_mat_log = X_log.as_matrix()\n",
    "X_train_log, X_test_log, y_train_log, y_test_log = train_test_split(X_mat_log, y_log, test_size=0.3, stratify=y_log, \n",
    "                                                                    random_state=rs)\n",
    "\n",
    "# standardise them again\n",
    "scaler_log = StandardScaler()\n",
    "X_train_log = scaler_log.fit_transform(X_train_log, y_train_log)\n",
    "X_test_log = scaler_log.transform(X_test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.813641038827\n",
      "Test accuracy: 0.815359232038\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.94      0.88      5015\n",
      "          1       0.72      0.42      0.53      1652\n",
      "\n",
      "avg / total       0.80      0.82      0.80      6667\n",
      "\n",
      "{'alpha': 0.0001, 'hidden_layer_sizes': (7,)}\n"
     ]
    }
   ],
   "source": [
    "params = {'hidden_layer_sizes': [(3,), (5,), (7,), (9,)], 'alpha': [0.01,0.001, 0.0001, 0.00001]}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params, estimator=MLPClassifier(random_state=rs), cv=10, n_jobs=-1)\n",
    "cv.fit(X_train_log, y_train_log)\n",
    "\n",
    "print(\"Train accuracy:\", cv.score(X_train_log, y_train_log))\n",
    "print(\"Test accuracy:\", cv.score(X_test_log, y_test_log))\n",
    "\n",
    "y_pred = cv.predict(X_test_log)\n",
    "print(classification_report(y_test_log, y_pred))\n",
    "\n",
    "print(cv.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "rfe = RFECV(estimator = LogisticRegression(random_state=rs), cv=10)\n",
    "rfe.fit(X_train_log, y_train_log)\n",
    "\n",
    "print(rfe.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.812612496786\n",
      "Test accuracy: 0.819559022049\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.95      0.89      5015\n",
      "          1       0.73      0.43      0.54      1652\n",
      "\n",
      "avg / total       0.81      0.82      0.80      6667\n",
      "\n",
      "{'alpha': 0.001, 'hidden_layer_sizes': (9,)}\n"
     ]
    }
   ],
   "source": [
    "# transform log \n",
    "X_train_rfe = rfe.transform(X_train_log)\n",
    "X_test_rfe = rfe.transform(X_test_log)\n",
    "\n",
    "# step = int((X_train_rfe.shape[1] + 5)/5);\n",
    "params = {'hidden_layer_sizes': [(3,), (5,), (7,), (9,)], 'alpha': [0.01,0.001, 0.0001, 0.00001]}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params, estimator=MLPClassifier(random_state=rs), cv=10, n_jobs=-1)\n",
    "cv.fit(X_train_rfe, y_train_log)\n",
    "\n",
    "print(\"Train accuracy:\", cv.score(X_train_rfe, y_train_log))\n",
    "print(\"Test accuracy:\", cv.score(X_test_rfe, y_test_log))\n",
    "\n",
    "y_pred = cv.predict(X_test_rfe)\n",
    "print(classification_report(y_test_log, y_pred))\n",
    "\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=10,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'criterion': ['gini', 'entropy'], 'max_depth': (2, 7), 'min_samples_leaf': range(10, 60, 10)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "params = {'criterion': ['gini', 'entropy'],\n",
    "          'max_depth': (2, 7),\n",
    "          'min_samples_leaf': range(10, 60, 10)}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params, estimator=DecisionTreeClassifier(random_state=rs), cv=10)\n",
    "cv.fit(X_train_log, y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGE : 0.472357701337\n",
      "AFFL : 0.307108179854\n",
      "GENDER_F : 0.154030659391\n",
      "BILL : 0.0139631481726\n",
      "GENDER_U : 0.0124680351293\n",
      "LTIME : 0.0118353590165\n",
      "GENDER_M : 0.00641199854201\n",
      "NGROUP_D : 0.00321957784075\n",
      "CLASS_Gold : 0.00274400229255\n",
      "NGROUP_C : 0.00226068376193\n",
      "TV_REG_London : 0.00192915166357\n",
      "REGION_Scottish : 0.00176643391756\n",
      "TV_REG_N East : 0.00141801614302\n",
      "TV_REG_S & S East : 0.00137564171039\n",
      "NGROUP_B : 0.00136906635238\n",
      "NGROUP_E : 0.00134709844487\n",
      "REGION_South East : 0.00120588379591\n",
      "TV_REG_S West : 0.000903471373456\n",
      "CLASS_Silver : 0.000880473869656\n",
      "REGION_Midlands : 0.000736633602924\n"
     ]
    }
   ],
   "source": [
    "tools.analyse_feature_importance(cv.best_estimator_, X_log.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15556, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# use the trained best decision tree from GridSearchCV to select features\n",
    "# supply the prefit=True parameter to stop SelectFromModel to re-train the model\n",
    "selectmodel = SelectFromModel(cv.best_estimator_, prefit=True)\n",
    "X_train_sel_model = selectmodel.transform(X_train_log)\n",
    "X_test_sel_model = selectmodel.transform(X_test_log)\n",
    "\n",
    "print(X_train_sel_model.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GridSearchCV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-41e88ed1f903>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_sel_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GridSearchCV' is not defined"
     ]
    }
   ],
   "source": [
    "params = {'C': [pow(10, x) for x in range(-6, 4)]}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params, estimator=LogisticRegression(random_state=rs), cv=10, n_jobs=-1)\n",
    "cv.fit(X_train_sel_model, y_train_log)\n",
    "\n",
    "print(\"Train accuracy:\", cv.score(X_train_sel_model, y_train_log))\n",
    "print(\"Test accuracy:\", cv.score(X_test_sel_model, y_test_log))\n",
    "\n",
    "# test the best model\n",
    "y_pred = cv.predict(X_test_sel_model)\n",
    "print(classification_report(y_test_log, y_pred))\n",
    "\n",
    "# print parameters of the best model\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
